<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>CSC415 - Introduction to Reinforcement Learning | Ameya Pore</title> <meta name="author" content="Ameya Pore"> <meta name="description" content="Course website for CSC415H5S Introduction to Reinforcement Learning - Winter 2026"> <meta name="keywords" content="Robotics, Deep Reinforcement learning, Surgical robots, Autonomy, Control"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%B2&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ameyapores.github.io/csc415/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">CSC415 - Introduction to Reinforcement Learning</h1> <p class="post-description">Course website for CSC415H5S Introduction to Reinforcement Learning - Winter 2026</p> </header> <article> <div class="card mb-4"> <div class="card-body"> <h2 class="card-title mb-3">Welcome to CSC415H5S</h2> <p class="card-text lead"> <strong>Introduction to Reinforcement Learning</strong><br> <em>Winter 2026 • University of Toronto Mississauga</em> </p> <p class="card-text"> Reinforcement learning is a powerful paradigm for modeling autonomous and intelligent agents interacting with the environment, and it is relevant to an enormous range of tasks, including robotics, game playing, consumer modeling and healthcare. This course provides an introduction to reinforcement learning intelligence, focusing on the study and design of agents that interact with a complex, uncertain world to achieve a goal. We will study agents that can make near-optimal decisions in a timely manner with incomplete information and limited computational resources. </p> <p class="card-text"> <strong>The course will cover (among other topics):</strong> </p> <ul class="card-text"> <li><strong>Markov Decision Processes (MDPs)</strong></li> <li> <strong>Reinforcement Learning</strong> algorithms</li> <li> <strong>Planning</strong> methods</li> <li> <strong>Function Approximation</strong> (online supervised learning)</li> </ul> <p class="card-text"> <em>Note: The topics listed above represent a limited selection from the course. Additional topics will be covered throughout the semester.</em> </p> </div> </div> <hr> <h2 id="course-information">Course Information</h2> <div class="row"> <div class="col-md-6"> <div class="card mb-3"> <div class="card-header"> <h5 class="mb-0"> <i class="fas fa-calendar-alt"></i> Schedule</h5> </div> <div class="card-body"> <p class="mb-2"><strong>Lecture (LEC0101):</strong><br> Wednesday, 11:00 AM - 1:00 PM<br> <em>In Person: DH 2070</em></p> <p class="mb-0"><strong>Practical (PRA0101):</strong><br> Thursday, 7:00 PM - 8:00 PM<br> <em>In Person: DH 2026</em></p> </div> </div> </div> <div class="col-md-6"> <div class="card mb-3"> <div class="card-header"> <h5 class="mb-0"> <i class="fas fa-user-tie"></i> Instructor</h5> </div> <div class="card-body"> <p class="mb-2"><strong>Dr. Ameya Pore</strong><br> <a href="mailto:amey.pore@utoronto.ca">amey.pore@utoronto.ca</a></p> <p class="mb-0"><strong>Office Hours:</strong><br> Wednesday, 6:00 PM - 7:00 PM<br> <em>In Person: MN3110</em></p> <small class="text-muted">Please allow 24-48 hours for response during regular business hours. Include [CSC415] in the subject line.</small> </div> </div> </div> </div> <div class="row"> <div class="col-md-12"> <div class="card mb-3"> <div class="card-header"> <h5 class="mb-0"> <i class="fas fa-users"></i> Teaching Assistants</h5> </div> <div class="card-body"> <div class="row"> <div class="col-md-6"> <p class="mb-2"><strong>Deniz Jafari</strong><br> <strong>Office Hours:</strong><br> <em>TBA</em></p> </div> <div class="col-md-6"> <p class="mb-2"><strong>Quentin Clark</strong><br> <strong>Office Hours:</strong><br> <em>TBA</em></p> </div> </div> </div> </div> </div> </div> <hr> <h3 id="learning-outcomes">Learning Outcomes</h3> <p>By the end of this course, students will be able to:</p> <ol> <li> <strong>Theoretically analyze</strong> and <strong>practically implement</strong> fundamental and advanced Reinforcement Learning algorithms, ranging from tabular methods and DQN to Policy Gradients (PPO)</li> <li> <strong>Design and execute</strong> a research project that applies these concepts to domains such as robotics (both simulation and real-world robots)</li> <li> <strong>Communicate findings</strong> through a conference-level research paper</li> <li> <strong>Critically evaluate</strong> the work of peers</li> <li> <strong>Effectively defend</strong> technical decisions through oral presentations</li> </ol> <h3 id="prerequisites">Prerequisites</h3> <ul> <li> <strong>Prerequisites:</strong> CSC311H5</li> <li> <strong>Recommended:</strong> CSC413</li> <li> <strong>Credit Value:</strong> 0.5</li> </ul> <hr> <h2 id="announcements">Announcements</h2> <div class="card mb-3"> <div class="card-body"> <h5 class="card-title">Welcome to CSC415!</h5> <p class="card-text"> Welcome to Introduction to Reinforcement Learning! This page will be updated regularly with course materials, announcements, and important information. Please check back frequently for updates. </p> <small class="text-muted">Posted: Course Start Date</small> </div> </div> <hr> <h2 id="course-materials">Course Materials</h2> <h3 id="required-textbook">Required Textbook</h3> <div class="card mb-3"> <div class="card-body"> <h5 class="card-title">Reinforcement Learning: An Introduction (2nd Edition)</h5> <p class="card-text mb-2"> <strong>Authors:</strong> Richard S. Sutton and Andrew G. Barto<br> <strong>Available online:</strong> <a href="http://incompleteideas.net/book/" target="_blank" rel="external nofollow noopener">http://incompleteideas.net/book/</a> </p> <p class="card-text mb-0"> <small class="text-muted"> This textbook covers foundational theory (MDPs, Bellman equations, TD learning) extensively. Best for Weeks 1–3 of the syllabus (Foundations, MC, TD). </small> </p> </div> </div> <h3 id="additional-resources">Additional Resources</h3> <p>The course draws inspiration from several excellent open-source courses and resources:</p> <ul> <li> <strong><a href="http://incompleteideas.net/book/" rel="external nofollow noopener" target="_blank">Sutton &amp; Barto Textbook</a></strong> - Reinforcement Learning: An Introduction (Free online)</li> <li> <strong><a href="https://amfarahmand.github.io/IntroRL/" rel="external nofollow noopener" target="_blank">Introduction to Reinforcement Learning</a></strong> by Amir-massoud Farahmand - A course on RL with emphasis on theoretical foundations</li> <li> <strong><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="external nofollow noopener" target="_blank">UCL Course on Reinforcement Learning</a></strong> by David Silver (DeepMind)</li> <li> <strong><a href="https://cs224r.stanford.edu/" rel="external nofollow noopener" target="_blank">Stanford CS224R: Deep Reinforcement Learning</a></strong> by Chelsea Finn</li> <li> <strong><a href="https://spinningup.openai.com/" rel="external nofollow noopener" target="_blank">OpenAI Spinning Up</a></strong> - RL Resources and implementations</li> <li> <strong>Berkeley Deep RL Course</strong> (various instructors)</li> </ul> <hr> <h2 id="assessment--grading">Assessment &amp; Grading</h2> <div class="table-responsive"> <table class="table table-hover"> <thead class="thead-light"> <tr> <th>Assessment</th> <th>Weight</th> <th>Due Date</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><strong>Laboratory Exercises</strong></td> <td>25%</td> <td>Various dates</td> <td>6 lab exercises (top 5 count). Hands-on programming assignments in Python using Gymnasium and PyTorch. Implement algorithms from tabular methods to DQN and PPO.</td> </tr> <tr class="table-warning"> <td><strong>Midterm Exam</strong></td> <td>15%</td> <td>Jan 29, 2026</td> <td><em>Written test covering foundational concepts from Weeks 1-4: MDPs, Bellman Equations, Q-Learning, and Policy Gradients.</em></td> </tr> <tr> <td><strong>Assignment 1</strong></td> <td>10%</td> <td>Feb 13, 2026</td> <td>Literature review of assigned papers (2-3 papers) along with code implementation of one of the papers.</td> </tr> <tr> <td><strong>Project Proposal</strong></td> <td>5%</td> <td>Feb 24, 2026</td> <td>Concise document outlining selected research topic, intended environment/dataset, and hypothesis.</td> </tr> <tr> <td><strong>Final Project Paper</strong></td> <td>25%</td> <td>Mar 24, 2026</td> <td>Comprehensive research paper in conference format (e.g., ICML/ICRA style) detailing methodology, experimental setup, results, and discussion.</td> </tr> <tr> <td><strong>Assignment 2 (Peer Review)</strong></td> <td>10%</td> <td>Mar 31, 2026</td> <td>Critical evaluation of peer project reports, providing constructive feedback on technical correctness, clarity, and novelty.</td> </tr> <tr> <td><strong>Final Project Presentation</strong></td> <td>10%</td> <td>Apr 2, 2026</td> <td>10-minute oral presentation of research findings, methodology, and analysis.</td> </tr> </tbody> </table> </div> <h3 id="lab-exercise-schedule">Lab Exercise Schedule</h3> <table> <thead> <tr> <th>Lab</th> <th>Due Date</th> <th>Topic</th> </tr> </thead> <tbody> <tr> <td>Lab 1</td> <td>Jan 13, 2026</td> <td>Tabular value-iteration agent on Gridworld</td> </tr> <tr> <td>Lab 2</td> <td>Jan 20, 2026</td> <td>Compare MC and TD methods; Q-Learning with ε-greedy</td> </tr> <tr> <td>Lab 3</td> <td>Jan 27, 2026</td> <td>Implement DQN in Gymnasium (CartPole or MountainCar)</td> </tr> <tr> <td>Lab 4</td> <td>Feb 17, 2026</td> <td>Train PPO agent on Pendulum-v1 (dm_control)</td> </tr> <tr> <td>Lab 5</td> <td>Mar 3, 2026</td> <td>Implement RND agent in MiniGrid or Maze2D</td> </tr> <tr> <td>Lab 6</td> <td>Mar 10, 2026</td> <td>Train CNN encoder on Atari frames; visualize latent space</td> </tr> </tbody> </table> <hr> <h2 id="course-schedule">Course Schedule</h2> <div class="card mb-4"> <div class="card-header"> <h5 class="mb-0"> <i class="fas fa-book"></i> Weekly Schedule</h5> </div> <div class="card-body"> <div class="table-responsive"> <table class="table table-sm"> <thead> <tr> <th>Week</th> <th>Date</th> <th>Topic</th> <th>Key Concepts</th> </tr> </thead> <tbody> <tr> <td><strong>1</strong></td> <td>Jan 7</td> <td>Foundations of Reinforcement Learning</td> <td>Agent–environment loop, MDP structure, value functions, Bellman equations, biological motivation</td> </tr> <tr> <td><strong>2</strong></td> <td>Jan 14</td> <td>Monte Carlo &amp; Temporal-Difference Learning</td> <td>MC prediction (first/every visit), TD(0), TD(λ), SARSA, on/off-policy learning</td> </tr> <tr> <td><strong>3</strong></td> <td>Jan 21</td> <td>Q-Learning</td> <td>Q-Learning algorithm, bias–variance trade-off, linear value approximation</td> </tr> <tr> <td><strong>4</strong></td> <td>Jan 28</td> <td>Function Approximation &amp; DQN</td> <td>Deep Q-Networks (DQN), Policy-Gradient Theorem, REINFORCE with baseline</td> </tr> <tr> <td><strong>5</strong></td> <td>Feb 4</td> <td>Policy Gradient Methods (PPO)</td> <td>REINFORCE → A2C → PPO, trust-region optimization, GAE, training stability</td> </tr> <tr> <td><strong>6</strong></td> <td>Feb 11</td> <td>Exploration in RL</td> <td>Entropy regularization, intrinsic motivation (ICM, RND), robustness and generalization</td> </tr> <tr> <td><strong>7</strong></td> <td>Feb 25</td> <td>Regularization and Representation Learning</td> <td>Contrastive learning (CURL, BYOL-Explore), predictive state representations, auxiliary tasks</td> </tr> <tr> <td><strong>8</strong></td> <td>Mar 4</td> <td>RL for Robotics (Embodied RL)</td> <td>Continuous control policies, sim-to-real transfer, domain randomization, hybrid IL + RL strategies</td> </tr> <tr> <td><strong>9</strong></td> <td>Mar 11</td> <td>World Models &amp; Latent Planning</td> <td>Latent dynamics models (VAE, RSSM, Dreamer), imagination rollouts, planning in latent space</td> </tr> <tr> <td><strong>10</strong></td> <td>Mar 18</td> <td>RL for LLMs and Alignment (RLHF)</td> <td>Preference modeling, reward models, PPO/DPO/RLAIF, alignment issues, reward mis-specification</td> </tr> <tr> <td><strong>11</strong></td> <td>Mar 28</td> <td>Sequence Modelling in RL</td> <td>Recurrent neural networks (RNNs, LSTMs, GRUs) for RL, Transformers in RL, Decision Transformers, trajectory transformers, history encoding, temporal dependencies, memory-augmented RL</td> </tr> <tr> <td><strong>12</strong></td> <td>Apr 2</td> <td>Final Project Presentations</td> <td>Student presentations of term projects (oral defense)</td> </tr> <tr> <td> <strong>13</strong> <em>(Optional)</em> </td> <td>Apr 9</td> <td>Safe-RL and Hierarchical RL</td> <td>Safe MDPs, constraint optimization, Lyapunov-based safety, CPO, risk-sensitive criteria, hierarchical task decomposition, options framework, HRL architectures</td> </tr> </tbody> </table> </div> </div> </div> <hr> <h2 id="project-information">Project Information</h2> <h3 id="final-project">Final Project</h3> <p>The course culminates in a capstone research project where students produce a conference-level paper. This is the primary deliverable for the course.</p> <div class="row"> <div class="col-md-6"> <div class="card mb-3"> <div class="card-header bg-primary text-white"> <h6 class="mb-0"> <i class="fas fa-file-alt"></i> Project Guidelines</h6> </div> <div class="card-body"> <p class="card-text">Comprehensive guidelines for the final project, including format requirements, evaluation criteria, and submission instructions.</p> <a href="/assets/pdf/csc415_project_guideline.pdf" class="btn btn-sm btn-primary" target="_blank"> <i class="fas fa-download"></i> Download Guidelines </a> </div> </div> </div> <div class="col-md-6"> <div class="card mb-3"> <div class="card-header bg-success text-white"> <h6 class="mb-0"> <i class="fas fa-lightbulb"></i> Project Topics</h6> </div> <div class="card-body"> <p class="card-text">Suggested research topics and project ideas to help you get started on your final project.</p> <a href="/assets/pdf/csc415_project_topics.pdf" class="btn btn-sm btn-success" target="_blank"> <i class="fas fa-download"></i> View Topics </a> </div> </div> </div> </div> <div class="card mb-3"> <div class="card-header bg-info text-white"> <h6 class="mb-0"> <i class="fas fa-cogs"></i> Simulation Setup</h6> </div> <div class="card-body"> <p class="card-text">Instructions for setting up simulation environments for your RL experiments, including Gymnasium, dm_control, and other relevant frameworks.</p> <a href="/assets/pdf/csc415_simulation_setup.pdf" class="btn btn-sm btn-info" target="_blank"> <i class="fas fa-download"></i> Download Setup Guide </a> </div> </div> <h3 id="project-timeline">Project Timeline</h3> <ul> <li> <strong>Feb 24, 2026:</strong> Project Proposal Due (5%)</li> <li> <strong>Mar 24, 2026:</strong> Final Project Paper Due (25%)</li> <li> <strong>Mar 31, 2026:</strong> Peer Review Due (10%)</li> <li> <strong>Apr 2, 2026:</strong> Final Project Presentation (10%)</li> </ul> <hr> <h2 id="course-policies">Course Policies</h2> <h3 id="late-submission-policy">Late Submission Policy</h3> <div class="alert alert-warning" role="alert"> <h5 class="alert-heading"> <i class="fas fa-exclamation-triangle"></i> Important Deadlines</h5> <hr> <p class="mb-2"><strong>Laboratory Exercises:</strong> Late submissions are <strong>prohibited</strong>. No late work will be accepted for the laboratory component.</p> <p class="mb-0"><strong>Assignments and Project Deliverables:</strong> Late submissions permitted for a maximum of <strong>3 days</strong> following the deadline. A penalty of <strong>15% per day</strong> will be deducted. Submissions made more than 3 days after the deadline will not be accepted.</p> </div> <h3 id="attendance">Attendance</h3> <p>Success in this course is highly correlated with active participation in both lectures and tutorial sessions. While attendance is not strictly graded for standard lectures, students are strongly encouraged to attend in person.</p> <div class="alert alert-info" role="alert"> <strong>Note:</strong> Attendance is <strong>mandatory</strong> for the Final Project Presentations in Week 12, as peer interaction is a core learning outcome. </div> <h3 id="academic-integrity">Academic Integrity</h3> <p>All work submitted must be your own. Collaboration on assignments is allowed but must be acknowledged. Plagiarism or any form of academic dishonesty will result in severe penalties, including possible failure of the course.</p> <p>Please familiarize yourself with the <a href="https://governingcouncil.utoronto.ca/secretariat/policies/code-behaviour-academic-matters-july-1-2019" rel="external nofollow noopener" target="_blank">Code of Behaviour on Academic Matters</a> and the <a href="https://www.utoronto.ca/student-affairs/code-student-conduct" rel="external nofollow noopener" target="_blank">Code of Student Conduct</a>.</p> <h3 id="generative-ai-policy">Generative AI Policy</h3> <div class="card mb-3"> <div class="card-body"> <h5 class="card-title">AI Tool Usage Guidelines</h5> <p class="card-text"> Students are <strong>permitted</strong> to use AI tools (e.g., ChatGPT, Claude, GitHub Copilot) as learning aids and to assist in assignments. However: </p> <ul> <li>Students remain <strong>ultimately accountable</strong> for all work submitted</li> <li> <strong>Citation is required:</strong> Any content, code, or ideas produced by AI must be explicitly cited</li> <li>Include an "AI Statement" at the end of assignments detailing which tools were used and for what purpose</li> <li> <strong>No grading penalty</strong> for declared use of AI tools, provided they are cited correctly</li> <li> <strong>Midterm Exam:</strong> Closed environment - use of AI tools/electronic devices is strictly prohibited</li> </ul> </div> </div> <h3 id="accommodations">Accommodations</h3> <ul> <li> <strong>Religious Accommodations:</strong> Information available at the <a href="https://www.viceprovoststudents.utoronto.ca/student-resources/rights-responsibilities/accommodation-religious/" rel="external nofollow noopener" target="_blank">University’s Policy on Scheduling</a> </li> <li> <strong>Temporary Absence:</strong> Students may use the ACORN Absence Declaration Tool for absences up to 7 consecutive days</li> <li> <strong>Equity and Academic Rights:</strong> The University of Toronto is committed to equity, meaningful inclusion, and respect for diversity</li> </ul> <hr> <h2 id="contact">Contact</h2> <p>For questions about the course:</p> <ol> <li> <strong>Check this website</strong> and announcements first</li> <li> <strong>Attend office hours:</strong> Wednesday, 6:00 PM - 7:00 PM (DH3110)</li> <li> <strong>Email the instructor:</strong> amey.pore@utoronto.ca <ul> <li>Please include <strong>[CSC415]</strong> in the subject line</li> <li>Allow 24-48 hours for response during regular business hours</li> </ul> </li> </ol> <hr> <div class="text-center text-muted mt-4"> <small>Last updated: December 29, 2025</small> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Ameya Pore. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>